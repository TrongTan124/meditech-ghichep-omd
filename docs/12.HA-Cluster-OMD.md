# Cấu hình Cluster cho check_mk - OMD

### Menu

- [1. Chuẩn bị](#1)
	- [Yêu cầu hệ thống](#11)
	- [Mô hình triển khai](#12)
	- [Bảng phân hoạch IP](#13)
- [2. Các bước cài đặt](#2)
	- [2.1 Đồng nhất thời gian giữa 2 server](#21)
	- [2.2 Cấu hình LVM trên 2 server](#22)
	- [2.3 Cấu hình hostname](#23)
	- [2.4 Cài đặt và cấu hình DRBD trên 2 server](#24)
	- [2.5 Cài đặt check_mk](#25)
	- [2.6 Cài đặt và cấu hình Pacemaker và Corosync trên 2 server](#26)
	- [2.7 Thêm các Resource vào Pacemaker](#27)
	- [2.8 Thêm site mới khi cấu hình xong HA Cluster cho OMD](#28)
- [3. Tham khảo](#3)

<a name="1" />
	
## 1. Chuẩn bị

<a name="11" />

- **Yêu cầu hệ thống:**
	- Hệ điều hành CentOS 7
	- Mỗi server gắn thêm một ổ cứng 5GB: `/dev/sdb`
	- Mỗi server có 2 card mạng
	- Tắt SELinux trên cả 2 server
	- Đồng nhất thời gian trên 2 server
	- Virtual IP: 192.168.100.123
	- Mở các port sau:
		- **Apache**: 80
		- **DRBD**: 5778
		- **Pacemaker/Corosync**: [Chi tiết](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/high_availability_add-on_reference/s1-firewalls-haar)
		
<a name="12" />

- **Mô hình triển khai**

<img src="/images/HA-OMD-check_mk.png" width=70% />

<a name="13" />

- **Bảng phân hoạch IP cho các máy chủ**

<img src="/images/HA-omd-ip.png" />

Link Online: https://goo.gl/N8FFmz

- Chú thích:
	- Dải 192.168.100.0/24 phục vụ cho việc ra ngoài Internet
	- Dải 172.16.1.0/24 phục vụ cho việc đồng bộ dữ liệu giữa 2 server
	
<a name="2" />

## 2. Các bước cài đặt

<a name="21" />

### 2.1 Đồng nhất thời gian giữa 2 server

- Để cấu hình được cluster, chúng ta sẽ phải đồng nhất thời gian cho 2 server. Trên cả 2 server, chọn múi giờ `Asia/Ho_Chi_Minh` và cài gói `ntp` để đồng bộ thời gian.

```
timedatectl set-timezone Asia/Ho_Chi_Minh
yum install ntp -y
ntpdate pool.ntp.org
```

<a name="22" />

### 2.2 Cấu hình LVM trên 2 server

- Như liệt kê ở phần chuẩn bị, chúng ta gắn thêm một ổ cứng 5GB và cấu hình trên mỗi server.
- Trên cả 2 node, chúng ta tạo một LVM để lưu trữ các dữ liệu có tên là `/dev/vgdrbd/vol1`. Ở đây, /dev/sdb được sử dụng để tạo LVM.

```
[root@omd1 ~]# pvcreate /dev/sdb
  Physical volume "/dev/sdb" successfully created
[root@omd1 ~]# vgcreate vgdrbd /dev/sdb
  Volume group "vgdrbd" successfully created
[root@omd1 ~]# lvcreate -n vol1 -l100%FREE vgdrbd
  Logical volume "vol1" created.
```

<a name="23" />

### 2.3 Cấu hình hostname

Trước khi cài đặt, chúng ta phải cấu hình hostname cho mỗi node và ghi chúng vào``hosts`.

- **Bước 1:** Cấu hình hostname

Trên server 1

```
[root@node1 ~] hostnamectl set-hostname omd1
```

Trên server 2

```
[root@node2 ~] hostnamectl set-hostname omd2
```

- **Bước 2:** Ghi thêm vào hosts của mỗi server

```
vi /etc/hosts
```

```
[...]
192.168.100.135 omd1
192.168.100.136 omd2
172.16.1.135 omddata1
172.16.1.136 omddata2
```

<a name="24" />

### 2.4 Cài đặt và cấu hình DRBD trên 2 server

- **Bước 1:** Cài đặt DRBD

	- Để cài đặt DRDB mới nhất, chúng ta thêm repo của DRDB (các thao tác này làm trên cả 2 node):

	```
	rpm -ivh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm
	```
	- Thêm Public key cho DRDB

	```
	rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-elrepo.org
	```
	- Tiếp theo, chúng ta cài đặt DRDB lần lượt trên cả 2 node:

	```
	yum -y install drbd84-utils kmod-drbd84
	```

	- Nếu quá trình cài đặt trên không thành công hoặc xảy ra lỗi hãy chèn lại key và tiếp tục cài đặt:

	```
	rpm --import /etc/pki/rpm-gpg/*
	```

	- Kích hoạt DRDB trên cả 2 node

	```
	modprobe drbd
	```

	- Kiểm tra DRDB đã hoạt động hay chưa:

	```
	lsmod | grep drbd

	drbd                  405309  0
	libcrc32c              12644  2 xfs,drbd
	```

- **Bước 2:** Cấu hình DRBD

	Chúng tạo một file có tên `testdata1.res` với nội dung như sau:

	```
	vi /etc/drbd.d/testdata1.res
	```

	```
	resource testdata1 {
	protocol C;          
	on omddata1 {
					device /dev/drbd0;
					disk /dev/vgdrbd/vol1;
					address 172.16.1.135:7788;
					meta-disk internal;
			}
	on omddata2 {
					device /dev/drbd0;
					disk /dev/vgdrbd/vol1;
					address 172.16.1.136:7788;
					meta-disk internal;
			}
	} 
	```
	
	Sao chép file cấu hình sang server 2:

	```
	[root@omd1 ~] scp /etc/drbd.d/testdata1.res node2:/etc/drbd.d/
	```

- **Bước 3:** Tạo và khởi động thiết bị DRBD	
		
	Khởi động trên mỗi node

	Trên server 1:

	```
	[root@omd1 ~] drbdadm create-md testdata1
	```

	Trên server 2:

	```
	[root@omd2 ~] drbdadm create-md testdata1
	```

	Khi thấy kết quả hiển thị như sau báo hiệu đã cấu hình thành công:

	```
	  --==  Thank you for participating in the global usage survey  ==--
	The server's response is:
	you are the 10680th user to install this version
	initializing activity log
	NOT initializing bitmap
	Writing meta data...
	New drbd meta data block successfully created.
	success
	```
	
	Ở trên 2 server, chúng ta bật và cho DRBD khởi động cùng hệ thống

	```
	systemctl start drbd
	systemctl enable drbd
	```

- **Bước 4:** Kích hoạt thiết bị DRBD

	Chúng tôi chọn node chính là `omd1`, chúng ta cũng có thể chọn `omd2` làm node chính bằng cách chạy lệnh này lên `omd2`.

	```
	[root@omd1 ~] drbdadm primary testdata1 --force
	```
	
	Kiểm tra trạng thái:

	```
	[root@omd1 ~]# cat /proc/drbd
	version: 8.4.7-1 (api:1/proto:86-101)
	GIT-hash: 3a6a769340ef93b1ba2792c6461250790795db49 build by phil@Build64R7, 2016-01-12 14:29:40
	 0: cs:Connected ro:Primary/Secondary ds:UpToDate/UpToDate C r-----
		ns:1048508 nr:0 dw:0 dr:1049236 al:8 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0
	```

	Hoặc dùng lệnh:

	```
	[root@omd1 ~]# drbd-overview
	 0:testdata1/0  Connected Primary/Secondary UpToDate/UpToDate
	```
	
- **Bước 5:** Cấu hình tường lửa trên cả 2 node
	
	```
	firewall-cmd --permanent --add-port=7788/tcp
	firewall-cmd --reload
	```

<a name="25" />
	
### 2.5 Cài đặt check_mk

- **Bước 1:** Cài đặt check_mk trên cả 2 node

```
yum install -y epel-release wget
wget https://mathias-kettner.de/support/1.2.8p21/check-mk-raw-1.2.8p21-el7-44.x86_64.rpm
yum install -y check-mk-raw-1.2.*
```

- **Bước 2:** Tạo một site mới trên `omd1`

```
omd create site1
```

- **Bước 3:** Xem thông tin user của site mới tạo trên `omd1`

```
root@omd1:~# id site1
uid=114(site1) gid=512(site1) Group=512(site1),103(omd)
```

- **Bước 4:** Tạo site mới tạo trên `omd2` với thông tin của user

```
omd create site1 -u 114 -g 512
```

**Lưu ý:** UID và GID phải trùng khớp với user tên `omd1`.

- **Bước 5:** Dừng hoạt động của site trên cả 2 node

```
omd stop site1
```

- **Bước 6:** Cấu hình tường lửa trên cả 2 node
	
	```
	firewall-cmd --permanent --add-port=80/tcp
	firewall-cmd --reload
	```

<a name="26" />
	
### 2.6 Cài đặt và cấu hình Pacemaker và Corosync trên 2 server

#### Cài đặt Pacemaker và Corosync

- **Bước 1:** Cài đặt các gói cluster trên cả 2 node bằng `yum`:

```
yum install -y pacemaker pcs fence-agents-all psmisc policycoreutils-python
```

- **Bước 2:** Chúng ta cấu hình tường lửa cho phép dịch vụ HA:

```
firewall-cmd --permanent --add-service=high-availability
firewall-cmd --reload
```

#### Cấu hình Cluster với Pacemaker và Corosync

- **Bước 1:** Tạo mật khẩu cho user `hacluster`

Trên cả 2 node, chúng ta đặt password cho user `hacluster` để xác thực với nhau, 2 mật khẩu phải trùng khớp.

```
echo "redhat" | passwd --stdin hacluster
```

- **Bước 2:** Khởi động dịch vụ trên cả 2 node:

```
systemctl start pcsd
systemctl enable pcsd
```

- **Bước 3:** Xác thực giữa 2 node 

Trên `omd1`, chúng ta xác thực 2 node với nhau bằng lệnh:

```
[root@omd1 ~]# pcs cluster auth omd1 omd2 -u hacluster -p redhat
omd1: Authorized
omd2: Authorized
```

- **Bước 4:** Tạo mới 1 cluster

Sau khi xác thực, chúng ta tạo 1 cluster trên omd1 có tên là `mycluster` để chúng có thể tạo và đồng bộ các file cấu hình với nhau.

```
[root@omd1 ~]# pcs cluster setup --name mycluster omd1 omd2
Shutting down pacemaker/corosync services...
Redirecting to /bin/systemctl stop  pacemaker.service
Redirecting to /bin/systemctl stop  corosync.service
Killing any remaining services...
Removing all cluster configuration files...
omd1: Succeeded
omd2: Succeeded
Synchronizing pcsd certificates on nodes omd1, omd2...
omd1: Success
omd2: Success
Restaring pcsd on the nodes in order to reload the certificates...
omd1: Success
omd2: Success
```

- **Bước 5:** Khởi động và kích hoạt cluster mới tạo trên omd1 bằng lệnh:

```
[root@omd1 ~]# pcs cluster start --all
[root@omd1 ~]# pcs cluster enable --all
```

Xem lại trạng thái của cluster trên các node:

```
pcs status
```

- **Bước 6:**  Tắt Quorum và STONITH

```
pcs property set stonith-enabled=false
pcs property set no-quorum-policy=ignore
pcs property set default-resource-stickiness="INFINITY"
```

<a name="27" />
	
### 2.7 Thêm các Resource vào Pacemaker 

*(Thực hiện trên 1 trong 2 node của cluster)*

#### Tắt tính năng tự khởi động của OMD và Apache

```
chkconfig omd off
chkconfig httpd off; systemctl disable httpd
```

#### Thêm Virtual IP

```
[root@omd1 ~]# pcs resource create VirtIP ocf:heartbeat:IPaddr2 ip=192.168.100.123 cidr_netmask=32 op monitor interval=30s
```

#### Thêm DRBD

Khi thiết bị DRBD trên `omd1` đang Active, thì trên `omd2`` ở chế độ Passive lưu trữ và đồng bộ dữ liệu từ `omd1`. Để làm như vậy, chúng ta gộp tài nguyên ở 2 node bằng cấu hình CIB:

```
[root@omd1 ~]# pcs cluster cib drbd_cfg
[root@omd1 ~]# pcs -f drbd_cfg resource create DrbdData ocf:linbit:drbd drbd_resource=testdata1 op monitor interval=60s
[root@omd1 ~]# pcs -f drbd_cfg resource master DrbdDataClone DrbdData master-max=1 master-node-max=1 clone-max=2 clone-node-max=1 notify=true
[root@omd1 ~]# pcs cluster cib-push drbd_cfg
```

**Lưu ý:** `testdata1` là tên của tài nguyên được khai báo trong file cấu hình DRBD.

- Kiểm tra:

```
[root@omd1 ~]# pcs status resources
 VirtIP (ocf::heartbeat:IPaddr2):       Started omd1
 Master/Slave Set: DrbdDataClone [DrbdData]
     Masters: [ omd1 ]
     Slaves: [ omd2 ]
```

#### Thêm FileSystem mount từ thiết bị DRBD

- **Bước 1:** Tạo thư mục chứa dữ liệu OMD

```
mkdir -p /opt/omddata
```

- **Bước 2:** Thêm resource, Mount thiết bị vào filesystem

```
[root@omd1 ~]# pcs cluster cib fs_cfg
[root@omd1 ~]# pcs -f fs_cfg resource create DrbdFS Filesystem device="/dev/drbd0" directory="/opt/omddata" fstype="ext3"
[root@omd1 ~]# pcs  -f fs_cfg constraint colocation add DrbdFS with DrbdDataClone INFINITY with-rsc-role=Master
[root@omd1 ~]# pcs  -f fs_cfg constraint order promote DrbdDataClone then start DrbdFS
Adding DrbdDataClone DrbdFS (kind: Mandatory) (Options: first-action=promote then-action=start)
[root@omd1 ~]# pcs cluster cib-push fs_cfg
CIB Updated
```

#### Thêm resource HTTPD

```
[root@omd1 ~]# pcs resource create Httpd ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf op monitor interval=1min
[root@omd1 ~]# pcs constraint colocation add Httpd with DrbdFS INFINITY
[root@omd1 ~]# pcs constraint order DrbdFS then Httpd
```

Kiểm tra lại thông tin

```
[root@omd1 ~]# pcs status resources
 VirtIP (ocf::heartbeat:IPaddr2):       Started omd1
 Master/Slave Set: DrbdDataClone [DrbdData]
     Masters: [ omd1 ]
     Slaves: [ omd2 ]
 Httpd  (ocf::heartbeat:apache):        Started omd1
```

#### Cấu hình OMD tạo thành Recource trong Pacemaker

- **Bước 1**: Dừng hoạt động của `site1` trên cả 2 node

```
omd stop site1
umount tmpfs
```

- **Bước 2**: Chuyển dữ liệu của OMD sang thiết bị DRBD

*Bước này làm trên node mà DRBD đang là Master.*

Chuyển dữ liệu và tạo symlink `versions` trong thư mục `/opt/omddata/`

```
[root@omd1 ~]# cd /opt/omd/
[root@omd1 ~]# mv apache/ /opt/omddata/
[root@omd1 ~]# mv sites/ /opt/omddata/
[root@omd1 ~]# ln -s /opt/omddata/apache/ apache
[root@omd1 ~]# ln -s /opt/omddata/sites/ sites

[root@omd1 ~]# cd /opt/omddata
[root@omd1 ~]# mdkir -p /opt/omddata/versions
[root@omd1 ~]# ln -s /opt/omd/versions/1.2.8p21.cre /opt/omddata/versions/1.2.8p21.cre
```

- **Bước 3**: Xóa dữ liệu của OMD trên node `omd2`

```
[root@omd2 ~]# cd /opt/omd
[root@omd2 ~]# rm -rf apache
[root@omd2 ~]# rm -rf sites
[root@omd2 ~]# ln -s /opt/omddata/apache/ /opt/omd/apache 
[root@omd2 ~]# ln -s /opt/omddata/sites/ /opt/omd/sites
```

- **Bước 4**: Thêm OCF Agent vào thư viện của Pacemaker

Tải và phân quyền cho Agent

```
[root@omd1 ~]# mkdir -p /usr/lib/ocf/resource.d/simon-meggle
[root@omd1 ~]# wget http://blog.simon-meggle.de/assets/omd-cluster-pacemaker-4/OMD.txt -O OMD
[root@omd1 ~]# chmod +x OMD
```

- **Bước 5**: Tạo resource cho site OMD trên Pacemaker

```
[root@omd1 ~]# pcs resource create omd-site1 ocf:simon-meggle:OMD site=site1 op monitor interval="10s" timeout="20s"  op start interval="0s" timeout="90s" op stop interval="0s" timeout="100s"
[root@omd1 ~]# pcs constraint colocation add DrbdFS with omd-site1
[root@omd1 ~]# pcs constraint order DrbdFS then omd-site1
```

Kiểm tra lại thông tin:

```
[root@omd1 tmp]# pcs resource
 VirtIP (ocf::heartbeat:IPaddr2):       Started omd1
 Httpd  (ocf::heartbeat:apache):        Started omd1
 Master/Slave Set: DrbdDataClone [DrbdData]
     Masters: [ omd1 ]
     Slaves: [ omd2 ]
 DrbdFS (ocf::heartbeat:Filesystem):    Started omd1
 omd-site1      (ocf::simon-meggle:OMD):        Started omd1

```

- **Bước 6:** Cấu hình RRDCached của OMD

Sửa file `vi /opt/omd/sites/site1/etc/rrdcached.conf`

```
# Data is written to disk every TIMEOUT seconds. If this option is
# not specified the default interval of 300 seconds will be used.
#TIMEOUT=3600
TIMEOUT=180

# rrdcached will delay writing of each RRD for a random
# number of seconds in the range [0,delay). This will avoid too many
# writes being queued simultaneously. This value should be no
# greater than the value specified in TIMEOUT.
#RANDOM_DELAY=1800
RANDOM_DELAY=90

# Every FLUSH_TIMEOUT seconds the entire cache is searched for old
values
# which are written to disk. This only concerns files to which
# updates have stopped, so setting this to a high value, such as
# 3600 seconds, is acceptable in most cases.
#FLUSH_TIMEOUT=7200
FLUSH_TIMEOUT=360
```

- Khởi động lại dịch vụ

```
omd reload site2 rrdcached 
```

<a name="28" />
	
### 2.8 Thêm site mới khi cấu hình xong HA Cluster cho OMD

- **Bước 1:** Tạo một site mới trên node đang hoạt động (Ví dụ: `omd1`)

```
[root@omd1 ~]# omd create site2
```

- **Bước 2:** Xem thông tin user `site2`

```
[root@omd1 ~]# cat /etc/fstab | grep site2 && cat /etc/passwd | grep site2
tmpfs  /opt/omd/sites/site2/tmp tmpfs noauto,user,mode=755,uid=site2,gid=site2 0 0
site2:x:992:1002:OMD site site2:/omd/sites/site2:/bin/bash
```

- **Bước 3:** Sang server `omd2`, ghi thông tin `site2` vào `/etc/fstab`

```
[root@omd2 ~]# echo "tmpfs  /opt/omd/sites/site2/tmp tmpfs noauto,user,mode=755,uid=site2,gid=site2 0 0" >> /etc/fstab
```

- **Bước 3:** Tạo thông tin cho user `site2` (Trên `omd2`)

```
[root@omd2 ~]# groupadd -g 1002 site2
[root@omd2 ~]# usermod -aG site2 apache
[root@omd2 ~]# useradd -u 992 site2 -d '/omd/sites/site2' -g site2 -G omd -s '/bin/bash'
```

- **Bước 4:** Tạo resource cho `site2` và cấu hình ràng buộc (Cấu hình trên server bất kỳ)

```
[root@omd2 ~]# pcs resource create omd-site2 ocf:simon-meggle:OMD site=site2 op monitor interval="10s" timeout="20s"  op start interval="0s" timeout="90s" op stop interval="0s" timeout="100s"

[root@omd2 ~]# pcs constraint colocation add DrbdFS with omd-site2
[root@omd2 ~]# pcs constraint order DrbdFS then omd-site2

[root@omd2 ~]# pcs resource cleanup --all
```

- **Bước 5:** Cấu hình RRDCached của OMD

Sửa file `vi /opt/omd/sites/site1/etc/rrdcached.conf`

```
# Data is written to disk every TIMEOUT seconds. If this option is
# not specified the default interval of 300 seconds will be used.
#TIMEOUT=3600
TIMEOUT=180

# rrdcached will delay writing of each RRD for a random
# number of seconds in the range [0,delay). This will avoid too many
# writes being queued simultaneously. This value should be no
# greater than the value specified in TIMEOUT.
#RANDOM_DELAY=1800
RANDOM_DELAY=90

# Every FLUSH_TIMEOUT seconds the entire cache is searched for old
values
# which are written to disk. This only concerns files to which
# updates have stopped, so setting this to a high value, such as
# 3600 seconds, is acceptable in most cases.
#FLUSH_TIMEOUT=7200
FLUSH_TIMEOUT=360
```

- Khởi động lại dịch vụ

```
omd reload site2 rrdcached 
```

<a name="3" />

### 3. Tham khảo:

- Cấu hình Pacemaker/Corosync: https://github.com/hoangdh/ghichep-HA/blob/master/Pacemaker_Corosync/2.Huong-dan-Pacemaker-Corosync-cho-Web-DRBD-CentOS.md#22-cài-đặt-pacemaker-và-corosync-
- Cấu hình DRBD: https://github.com/hoangdh/ghichep-DRBD/blob/master/Cau-hinh-DRBD-co-ban-tren-CentOS.md
- Cấu hình LVM: https://github.com/hoangdh/Su_dung_LVM
- Cài đặt OMD: https://github.com/meditechopen/meditech-ghichep-omd/blob/master/docs/1.1.Setup-OMD-CentOS7.md
- Cấu hình HA cho OMD: http://blog.simon-meggle.de/tutorials/nagiosomd-cluster-mit-pacemakerdrbd-teil-1/